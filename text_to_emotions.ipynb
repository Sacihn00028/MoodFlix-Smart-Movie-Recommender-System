{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c5322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moliktyagi/Desktop/Projects/MoodFlix-Smart-Movie-Recommender-System/dlhack/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4206df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/moliktyagi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/moliktyagi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6a190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 43410\n",
      "Validation samples: 5426\n",
      "Test samples: 5427\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "\"# Splits: train, validation, test\\n\",\n",
    "train_data = dataset[\"train\"]\n",
    "train_data = train_data.to_pandas()\n",
    "valid_data = dataset[\"validation\"]\n",
    "valid_data = valid_data.to_pandas()\n",
    "test_data = dataset[\"test\"]\n",
    "test_data = test_data.to_pandas()\n",
    "print(\"Training samples:\", len(train_data)),\n",
    "print(\"Validation samples:\", len(valid_data))\n",
    "print(\"Test samples:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0a73d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels       id\n",
       "0  My favourite food is anything I didn't have to...   [27]  eebbqej\n",
       "1  Now if he does off himself, everyone will thin...   [27]  ed00q6i\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj\n",
       "3                        To make her feel threatened   [14]  ed7ypvh\n",
       "4                             Dirty Southern Wankers    [3]  ed0bdzj"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd99a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43410 entries, 0 to 43409\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    43410 non-null  object\n",
      " 1   labels  43410 non-null  object\n",
      " 2   id      43410 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1017.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f491bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Class\"] = train_data[\"labels\"].apply(\n",
    "    lambda x: \",\".join(str(item) for item in x)\n",
    ")\n",
    "train_data[\"Class List\"] = train_data[\"Class\"].apply(lambda x: x.split(\",\"))\n",
    "train_data[\"Class Length\"] = train_data[\"Class List\"].apply(len)\n",
    "\n",
    "valid_data[\"Class\"] = valid_data[\"labels\"].apply(\n",
    "    lambda x: \",\".join(str(item) for item in x)\n",
    ")\n",
    "valid_data[\"Class List\"] = valid_data[\"Class\"].apply(lambda x: x.split(\",\"))\n",
    "valid_data[\"Class Length\"] = valid_data[\"Class List\"].apply(len)\n",
    "\n",
    "test_data[\"Class\"] = test_data[\"labels\"].apply(\n",
    "    lambda x: \",\".join(str(item) for item in x)\n",
    ")\n",
    "test_data[\"Class List\"] = test_data[\"Class\"].apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdde4e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Length\n",
       "1    36308\n",
       "2     6541\n",
       "3      532\n",
       "4       28\n",
       "5        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Class Length\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31b3a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': ['anger', 'annoyance', 'disapproval'],\n",
       " 'disgust': ['disgust'],\n",
       " 'fear': ['fear', 'nervousness'],\n",
       " 'joy': ['joy',\n",
       "  'amusement',\n",
       "  'approval',\n",
       "  'excitement',\n",
       "  'gratitude',\n",
       "  'love',\n",
       "  'optimism',\n",
       "  'relief',\n",
       "  'pride',\n",
       "  'admiration',\n",
       "  'desire',\n",
       "  'caring'],\n",
       " 'sadness': ['sadness', 'disappointment', 'embarrassment', 'grief', 'remorse'],\n",
       " 'surprise': ['surprise', 'realization', 'confusion', 'curiosity']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ekman_mapping.json') as file:\n",
    "    ekman_mapping = json.load(file)\n",
    "ekman_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db89d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "emotion_file = open(\"emotions.txt\", \"r\")\n",
    "emotion_list = emotion_file.read()\n",
    "emotion_list = emotion_list.split(\"\\n\")\n",
    "print(emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936681f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2class(idx_list):\n",
    "    arr = []\n",
    "    for i in idx_list:\n",
    "        arr.append(emotion_list[int(i)])\n",
    "    return arr\n",
    "train_data['Emotions'] = train_data['Class List'].apply(idx2class)\n",
    "valid_data['Emotions'] = valid_data['Class List'].apply(idx2class)\n",
    "test_data['Emotions'] = test_data['Class List'].apply(idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d0ba29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class List</th>\n",
       "      <th>Class Length</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "      <td>27</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "      <td>27</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>[anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "      <td>14</td>\n",
       "      <td>[14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "      <td>3</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1</td>\n",
       "      <td>[annoyance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels       id Class  \\\n",
       "0  My favourite food is anything I didn't have to...   [27]  eebbqej    27   \n",
       "1  Now if he does off himself, everyone will thin...   [27]  ed00q6i    27   \n",
       "2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj     2   \n",
       "3                        To make her feel threatened   [14]  ed7ypvh    14   \n",
       "4                             Dirty Southern Wankers    [3]  ed0bdzj     3   \n",
       "\n",
       "  Class List  Class Length     Emotions  \n",
       "0       [27]             1    [neutral]  \n",
       "1       [27]             1    [neutral]  \n",
       "2        [2]             1      [anger]  \n",
       "3       [14]             1       [fear]  \n",
       "4        [3]             1  [annoyance]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80dc29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_to_idx = {emotion: i for i, emotion in enumerate(emotion_list)}\n",
    "\n",
    "# Function to convert list of emotions to binary vector\n",
    "def encode_emotions(emotions):\n",
    "    vector = [0] * len(emotion_to_idx)\n",
    "    for emotion in emotions:\n",
    "        idx = emotion_to_idx[emotion]\n",
    "        vector[idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f2ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['emotion_vector'] = train_data['Emotions'].apply(encode_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1000983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class List</th>\n",
       "      <th>Class Length</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>emotion_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "      <td>27</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "      <td>27</td>\n",
       "      <td>[27]</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "      <td>[anger]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "      <td>14</td>\n",
       "      <td>[14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[fear]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "      <td>3</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1</td>\n",
       "      <td>[annoyance]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels       id Class  \\\n",
       "0  My favourite food is anything I didn't have to...   [27]  eebbqej    27   \n",
       "1  Now if he does off himself, everyone will thin...   [27]  ed00q6i    27   \n",
       "2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj     2   \n",
       "3                        To make her feel threatened   [14]  ed7ypvh    14   \n",
       "4                             Dirty Southern Wankers    [3]  ed0bdzj     3   \n",
       "\n",
       "  Class List  Class Length     Emotions  \\\n",
       "0       [27]             1    [neutral]   \n",
       "1       [27]             1    [neutral]   \n",
       "2        [2]             1      [anger]   \n",
       "3       [14]             1       [fear]   \n",
       "4        [3]             1  [annoyance]   \n",
       "\n",
       "                                      emotion_vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9768073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.texts = dataframe['text']\n",
    "        self.labels = dataframe['emotion_vector'].tolist()\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts.iloc[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length = self.max_len\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': torch.tensor(encoding['input_ids']),\n",
    "            'attention_mask': torch.tensor(encoding['attention_mask']),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c437e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "model_name = 'prajjwal1/bert-small'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "dataset = EmotionDataset(train_data, tokenizer, 512)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a2f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 28 \n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "# Use Binary Cross-Entropy Loss for multi-label classification\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer remains the same\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95cd45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you set the device to cuda:0 as the default\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to cuda:0 before applying DataParallel\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e44056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch  {'input_ids': tensor([[ 101, 2051, 2000,  ...,    0,    0,    0],\n",
      "        [ 101, 5580, 2000,  ...,    0,    0,    0],\n",
      "        [ 101, 6728, 6719,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 4067, 1031,  ...,    0,    0,    0],\n",
      "        [ 101, 3272, 2005,  ...,    0,    0,    0],\n",
      "        [ 101, 6516, 1996,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m loss = loss_fn(outputs.logits, labels)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Optimization step\u001b[39;00m\n\u001b[32m     30\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/MoodFlix-Smart-Movie-Recommender-System/dlhack/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/MoodFlix-Smart-Movie-Recommender-System/dlhack/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/MoodFlix-Smart-Movie-Recommender-System/dlhack/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# import torch_xla.core.xla_model as xm\n",
    "# device = xm.xla_device()\n",
    "model = model.to(device) \n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Replace 10 with the number of epochs you want\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(\"Training batch \" , batch)\n",
    "\n",
    "        # Move the input data to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().to(device)  # Ensure labels are float for BCEWithLogitsLoss\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss for this epoch\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Average epoch loss\n",
    "    avg_loss = epoch_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/kaggle/working/bert_emotion_classifier\"\n",
    "# Save the model\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model.module.save_pretrained(output_directory)\n",
    "else:\n",
    "    model.save_pretrained(output_directory)\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(output_directory)\n",
    "print(f\"Model saved as: {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f56c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
