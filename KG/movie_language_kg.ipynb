{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ba0c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GPU\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1baabad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTokenizerFast(name_or_path='facebook/bart-large-mnli', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9724d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lang.csv')\n",
    "\n",
    "language_dict = {\n",
    "    'en': 'English',\n",
    "    'ja': 'Japanese',\n",
    "    'fr': 'French',\n",
    "    'zh': 'Chinese',\n",
    "    'es': 'Spanish',\n",
    "    'de': 'German',\n",
    "    'hi': 'Hindi',\n",
    "    'ru': 'Russian',\n",
    "    'ko': 'Korean',\n",
    "    'te': 'Telugu',\n",
    "    'cn': 'Chinese',\n",
    "    'it': 'Italian',\n",
    "    'nl': 'Dutch',\n",
    "    'ta': 'Tamil',\n",
    "    'sv': 'Swedish',\n",
    "    'th': 'Thai',\n",
    "    'da': 'Danish',\n",
    "    'xx': 'Unknown',\n",
    "    'hu': 'Hungarian',\n",
    "    'cs': 'Czech',\n",
    "    'pt': 'Portuguese',\n",
    "    'is': 'Icelandic',\n",
    "    'tr': 'Turkish',\n",
    "    'nb': 'Norwegian Bokmål',\n",
    "    'af': 'Afrikaans',\n",
    "    'pl': 'Polish',\n",
    "    'he': 'Hebrew',\n",
    "    'ar': 'Arabic',\n",
    "    'vi': 'Vietnamese',\n",
    "    'ky': 'Kyrgyz',\n",
    "    'id': 'Indonesian',\n",
    "    'ro': 'Romanian',\n",
    "    'fa': 'Persian',\n",
    "    'no': 'Norwegian',\n",
    "    'sl': 'Slovenian',\n",
    "    'ps': 'Pashto',\n",
    "    'el': 'Greek'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8750aa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load summarizer (optimized for GPU if available)\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "\n",
    "# Load zero-shot classifier (for mood classification)\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Connect to Neo4j (replace with your credentials)\n",
    "uri = \"neo4j+s://0d57704b.databases.neo4j.io\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"5yPsvhzqDCZYx2s08eS3GvGLPM33v32IaQp-jEG3CdM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42356383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_text(text):\n",
    "#     input_length = len(text.split())\n",
    "#     max_len = min(50, input_length)  # avoid warning\n",
    "#     min_len = min(25, max_len-1) if max_len > 25 else 5\n",
    "#     summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)\n",
    "#     return summary[0]['summary_text']\n",
    "\n",
    "# def classify_director(text):\n",
    "#     return text\n",
    "\n",
    "def create_graph(tx, movie_data):\n",
    "    # Get full language name from the dictionary\n",
    "    language_name = language_dict.get(movie_data['language'], 'Unknown')\n",
    "    \n",
    "    # Create the Cypher query\n",
    "    tx.run(\"\"\"\n",
    "        // Create Language node\n",
    "        MERGE (l:Language {name: $language_name, code: $language_code})\n",
    "        \n",
    "        // Create Movie node with all properties\n",
    "        MERGE (m:Movie {title: $title})\n",
    "        SET m.year = $year,\n",
    "            m.runtime = $runtime,\n",
    "            m.vote_count = $vote_count,\n",
    "            m.revenue = $revenue,\n",
    "            m.overview = $overview,\n",
    "            m.genres = $genres\n",
    "        \n",
    "        // Create Director node\n",
    "        MERGE (d:Director {name: $director})\n",
    "        \n",
    "        // Create relationships\n",
    "        MERGE (l)-[:IN_LANGUAGE]->(m)\n",
    "        MERGE (d)-[:DIRECTED]->(m)\n",
    "        \"\"\", \n",
    "        language_name=language_name,\n",
    "        language_code=movie_data['language'],\n",
    "        title=movie_data['title'],\n",
    "        year=movie_data['year'],\n",
    "        runtime=movie_data['runtime'],\n",
    "        vote_count=movie_data['vote_count'],\n",
    "        revenue=movie_data['revenue'],\n",
    "        overview=movie_data['overview'],\n",
    "        genres=movie_data['genres'],\n",
    "        director=movie_data['director']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79faf6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4803/4803 [24:18<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Movie knowledge graph built successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset\n",
    "with driver.session() as session:\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        movie_data = {\n",
    "            'title': row['original_title'],\n",
    "            'language': row['original_language'],\n",
    "            'year': pd.to_datetime(row['release_date']).year,\n",
    "            'runtime': int(row['runtime']) if pd.notna(row['runtime']) else 0,\n",
    "            'vote_count': int(row['vote_count']) if pd.notna(row['vote_count']) else 0,\n",
    "            'revenue': float(row['revenue']) if pd.notna(row['revenue']) else 0.0,\n",
    "            'overview': str(row['overview']) if pd.notna(row['overview']) else '',\n",
    "            'genres': str(row['genres']) if pd.notna(row['genres']) else '',\n",
    "            'director': str(row['director']) if pd.notna(row['director']) else 'Unknown'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            session.execute_write(create_graph, movie_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {movie_data['title']}: {e}\")\n",
    "\n",
    "driver.close()\n",
    "print(\"✅ Movie knowledge graph built successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2139188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_1156\\100102250.py:1: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session() as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: 4503 movies\n",
      "French: 70 movies\n",
      "Chinese: 39 movies\n",
      "Spanish: 32 movies\n",
      "German: 27 movies\n"
     ]
    }
   ],
   "source": [
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (l:Language)-[r:IN_LANGUAGE]->(m:Movie)\n",
    "        RETURN l.name as Language, count(m) as MovieCount\n",
    "        ORDER BY MovieCount DESC\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    for record in result:\n",
    "        print(f\"{record['Language']}: {record['MovieCount']} movies\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
